---
name: crawl4ai
description: Complete toolkit for web crawling and data extraction. Use the `crawler` tool directly to scrape any website. Supports social media (TikTok, YouTube), GitHub, JavaScript-heavy pages, structured data extraction, and batch crawling.
version: 0.7.4
last_updated: 2026-02-23
---

# Crawl4AI â€” CÃ o & TrÃ­ch xuáº¥t Dá»¯ liá»‡u Web

## âš ï¸ QUAN TRá»ŒNG â€” Quy táº¯c báº¯t buá»™c

> **LUÃ”N LUÃ”N gá»i tool `crawler` trá»±c tiáº¿p.**
> **KHÃ”NG BAO GIá»œ** dÃ¹ng `exec` Ä‘á»ƒ `import crawl4ai` hoáº·c cháº¡y Python scripts.
> **KHÃ”NG BAO GIá»œ** dÃ¹ng `exec` Ä‘á»ƒ cháº¡y Docker commands.
> Tool `crawler` gá»i API server Crawl4AI tá»« xa â€” khÃ´ng cáº§n cÃ i thÆ° viá»‡n local.

```
# âœ… ÄÃšNG â€” Gá»i tool trá»±c tiáº¿p
crawler(url="https://example.com")

# âŒ SAI â€” KHÃ”NG lÃ m tháº¿ nÃ y
exec(command="python -c 'from crawl4ai import ...'")
exec(command="docker exec crawl4ai ...")
```

---

## âš¡ Sá»­ dá»¥ng Tool `crawler`

### Tham sá»‘

| Tham sá»‘ | Kiá»ƒu | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|-------|----------|-------|
| `url` | string | *(báº¯t buá»™c)* | URL cáº§n cÃ o |
| `css_selector` | string | â€” | Chá»‰ láº¥y ná»™i dung trong selector (VD: `.main-content`) |
| `extraction_schema` | object | â€” | JSON schema cho CSS-based extraction |
| `extraction_instruction` | string | â€” | Instruction cho LLM-based extraction |
| `js_code` | string | â€” | JavaScript cháº¡y trÆ°á»›c khi trÃ­ch xuáº¥t |
| `wait_for` | string | â€” | Äá»£i element xuáº¥t hiá»‡n (`css:.selector` hoáº·c `js:() => bool`) |
| `magic` | bool | false | Cháº¿ Ä‘á»™ tá»± nháº­n diá»‡n ná»™i dung + anti-bot |
| `session_id` | string | â€” | Reuse browser context (multi-step flows) |
| `virtual_scroll` | bool | false | Cuá»™n trang tá»± Ä‘á»™ng (cho TikTok/YouTube) |
| `scroll_count` | int | 10 | Sá»‘ láº§n cuá»™n khi `virtual_scroll=true` |
| `screenshot` | bool | false | Chá»¥p áº£nh trang |
| `exclude_social` | bool | true | Loáº¡i bá» link máº¡ng xÃ£ há»™i |
| `cookies` | array | â€” | Cookies cho auth |
| `headers` | object | â€” | Custom HTTP headers |

---

## ğŸ“– VÃ­ dá»¥ Sá»­ dá»¥ng

### CÃ o trang cÆ¡ báº£n
```
crawler(url="https://vnexpress.net")
```

### CÃ o kÃªnh TikTok (cuá»™n trang)
```
crawler(url="https://www.tiktok.com/@user", virtual_scroll=true, scroll_count=15)
```

### Láº¥y dá»¯ liá»‡u cá»¥ thá»ƒ vá»›i CSS selector
```
crawler(url="https://youtube.com/@channel/videos", css_selector="#contents ytd-rich-item-renderer")
```

### DÃ¹ng Magic Mode (anti-bot)
```
crawler(url="https://protected-site.com", magic=true)
```

### Cháº¡y JavaScript trÆ°á»›c khi cÃ o
```
crawler(url="https://example.com", js_code="document.querySelector('.load-more').click()", wait_for="css:.new-items")
```

### Structured extraction vá»›i schema
```
crawler(url="https://shop.com", extraction_schema={"name": "Products", "baseSelector": ".product", "fields": [{"name": "title", "selector": "h2", "type": "text"}, {"name": "price", "selector": ".price", "type": "text"}]})
```

### Multi-step login rá»“i cÃ o
```
crawler(url="https://site.com/login", session_id="my_session", js_code="document.querySelector('#user').value='admin'; document.querySelector('#pass').value='123'; document.querySelector('#submit').click();", wait_for="css:.dashboard")
crawler(url="https://site.com/data", session_id="my_session")
```

---

## ğŸ¬ CÃ o YouTube

> **QUAN TRá»ŒNG:** YouTube dÃ¹ng Web Components náº·ng, tool `crawler` (Crawl4AI API) thÆ°á»ng tráº£ markdown rá»—ng.
> **LuÃ´n dÃ¹ng tool `camofox`** cho YouTube â€” nÃ³ cháº¡y Playwright local, render JS Ä‘áº§y Ä‘á»§.

### CÃ o thÃ´ng tin video + comments
```
camofox(url="https://www.youtube.com/watch?v=VIDEO_ID")
```

### CÃ o danh sÃ¡ch video tá»« channel
```
camofox(url="https://www.youtube.com/@channel/videos")
```

### Tips cÃ o YouTube
- **LuÃ´n dÃ¹ng `camofox`**, KHÃ”NG dÃ¹ng `crawler` cho YouTube
- **KHÃ”NG dÃ¹ng `extraction_instruction`** â€” gÃ¢y lá»—i 500
- Káº¿t quáº£ tráº£ vá» dáº¡ng markdown â€” tá»± phÃ¢n tÃ­ch ná»™i dung tá»« Ä‘Ã³

---

## ğŸ™ CÃ o GitHub

### CÃ o Repository (README, code, file structure)
```
crawler(url="https://github.com/owner/repo")
```

### CÃ o Issues / Pull Requests
```
crawler(url="https://github.com/owner/repo/issues")
crawler(url="https://github.com/owner/repo/issues/123")
crawler(url="https://github.com/owner/repo/pulls")
```

### CÃ o Profile / Organization
```
crawler(url="https://github.com/username")
crawler(url="https://github.com/orgs/orgname")
```

### CÃ o Releases & Tags
```
crawler(url="https://github.com/owner/repo/releases")
```

### CÃ o File cá»¥ thá»ƒ (raw content)
```
crawler(url="https://raw.githubusercontent.com/owner/repo/main/README.md")
```

### CÃ o GitHub Search Results
```
crawler(url="https://github.com/search?q=crawl4ai+language:python&type=repositories")
```

### Tips cÃ o GitHub
- DÃ¹ng URL `raw.githubusercontent.com` Ä‘á»ƒ láº¥y raw file content
- DÃ¹ng `css_selector` Ä‘á»ƒ focus vÃ o pháº§n cá»¥ thá»ƒ (VD: `.markdown-body` cho README)
- GitHub API (`api.github.com`) tráº£ vá» JSON â€” dÃ¹ng `web_fetch` thay vÃ¬ `crawler`
- Vá»›i trang private, cáº§n auth headers hoáº·c dÃ¹ng `gh` CLI (xem skill `github`)

---

## Khi nÃ o dÃ¹ng tool `crawler`
- Khi user yÃªu cáº§u **cÃ o/scrape/crawl** trang web
- Khi cáº§n **láº¥y ná»™i dung** tá»« URL Ä‘á»ƒ phÃ¢n tÃ­ch
- Khi cáº§n **theo dÃµi/monitor** trang web, kÃªnh Social Media
- Khi WebFetch khÃ´ng Ä‘á»§ (trang cáº§n JS rendering)

## Output
- Tráº£ vá» ná»™i dung trang dáº¡ng **Markdown** (sáº¡ch, dá»… Ä‘á»c)
- Bao gá»“m metadata (tiÃªu Ä‘á», mÃ´ táº£), links, media
- Tá»± Ä‘á»™ng giá»›i háº¡n 12000 kÃ½ tá»± Ä‘á»ƒ khÃ´ng trÃ n context

## Tham kháº£o thÃªm
- Xem `references/complete-sdk-reference.md` Ä‘á»ƒ tra cá»©u SDK parameters nÃ¢ng cao
- Xem `scripts/` Ä‘á»ƒ cháº¡y batch crawling hoáº·c extraction pipeline thá»§ cÃ´ng
